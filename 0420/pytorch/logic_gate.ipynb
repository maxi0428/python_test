{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=np.array([[0,0],[0,1],[1,0],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate(x):\n",
    "    w1=0.5\n",
    "    w2=0.5\n",
    "    b=-0.7\n",
    "\n",
    "    result=x[0]*w1+x[1]*w2+b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(AND_gate(x))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND_gate(x):\n",
    "    w1=-0.5\n",
    "    w2=-0.5\n",
    "    b=0.7\n",
    "\n",
    "    result=x[0]*w1+x[1]*w2+b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(NAND_gate(x))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate(x):\n",
    "    w1=0.6\n",
    "    w2=0.6\n",
    "    b=-0.5\n",
    "\n",
    "    result=x[0]*w1+x[1]*w2+b\n",
    "    if result <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for x in input_data:\n",
    "    result.append(OR_gate(x))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=[] #nand 출력 결과\n",
    "s2=[] # or 출력 결과\n",
    "\n",
    "new_input=[] #and 입력\n",
    "final_output=[] # 최종 출력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_data)):\n",
    "    s1=NAND_gate(input_data[i])\n",
    "    s2=OR_gate(input_data[i])\n",
    "\n",
    "    new_input.append(s1)\n",
    "    new_input.append(s2)\n",
    "\n",
    "    result=AND_gate(new_input)\n",
    "    final_output.append(result)\n",
    "    new_input=[]\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_data=np.array([[0,0],[0,1],[1,0],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.from_numpy(input_data).float()\n",
    "Y=torch.FloatTensor([[1],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear=nn.Linear(2,1, bias=True)\n",
    "sigmoid=nn.Sigmoid()\n",
    "model=nn.Sequential(linear,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.815999448\n",
      "step: 100, cost: 0.143908024\n",
      "step: 200, cost: 0.081697226\n",
      "step: 300, cost: 0.056545556\n",
      "step: 400, cost: 0.043050714\n",
      "step: 500, cost: 0.034678418\n",
      "step: 600, cost: 0.028994828\n",
      "step: 700, cost: 0.024891941\n",
      "step: 800, cost: 0.021794494\n",
      "step: 900, cost: 0.019375436\n",
      "step: 1000, cost: 0.017435040\n",
      "step: 1100, cost: 0.015844757\n",
      "step: 1200, cost: 0.014518043\n",
      "step: 1300, cost: 0.013394799\n",
      "step: 1400, cost: 0.012431670\n",
      "step: 1500, cost: 0.011596857\n",
      "step: 1600, cost: 0.010866443\n",
      "step: 1700, cost: 0.010222033\n",
      "step: 1800, cost: 0.009649400\n",
      "step: 1900, cost: 0.009137133\n",
      "step: 2000, cost: 0.008676231\n",
      "step: 2100, cost: 0.008259412\n",
      "step: 2200, cost: 0.007880595\n",
      "step: 2300, cost: 0.007534851\n",
      "step: 2400, cost: 0.007218008\n",
      "step: 2500, cost: 0.006926704\n",
      "step: 2600, cost: 0.006657833\n",
      "step: 2700, cost: 0.006409009\n",
      "step: 2800, cost: 0.006178057\n",
      "step: 2900, cost: 0.005963043\n",
      "step: 3000, cost: 0.005762470\n",
      "step: 3100, cost: 0.005574885\n",
      "step: 3200, cost: 0.005399186\n",
      "step: 3300, cost: 0.005234099\n",
      "step: 3400, cost: 0.005078819\n",
      "step: 3500, cost: 0.004932388\n",
      "step: 3600, cost: 0.004794211\n",
      "step: 3700, cost: 0.004663475\n",
      "step: 3800, cost: 0.004539773\n",
      "step: 3900, cost: 0.004422345\n",
      "step: 4000, cost: 0.004310869\n",
      "step: 4100, cost: 0.004204853\n",
      "step: 4200, cost: 0.004103852\n",
      "step: 4300, cost: 0.004007649\n",
      "step: 4400, cost: 0.003915805\n",
      "step: 4500, cost: 0.003828091\n",
      "step: 4600, cost: 0.003744207\n",
      "step: 4700, cost: 0.003663938\n",
      "step: 4800, cost: 0.003586966\n",
      "step: 4900, cost: 0.003513193\n",
      "step: 5000, cost: 0.003442379\n",
      "step: 5100, cost: 0.003374397\n",
      "step: 5200, cost: 0.003308969\n",
      "step: 5300, cost: 0.003246094\n",
      "step: 5400, cost: 0.003185536\n",
      "step: 5500, cost: 0.003127150\n",
      "step: 5600, cost: 0.003070886\n",
      "step: 5700, cost: 0.003016634\n",
      "step: 5800, cost: 0.002964268\n",
      "step: 5900, cost: 0.002913619\n",
      "step: 6000, cost: 0.002864733\n",
      "step: 6100, cost: 0.002817424\n",
      "step: 6200, cost: 0.002771656\n",
      "step: 6300, cost: 0.002727362\n",
      "step: 6400, cost: 0.002684444\n",
      "step: 6500, cost: 0.002642879\n",
      "step: 6600, cost: 0.002602564\n",
      "step: 6700, cost: 0.002563433\n",
      "step: 6800, cost: 0.002525466\n",
      "step: 6900, cost: 0.002488633\n",
      "step: 7000, cost: 0.002452853\n",
      "step: 7100, cost: 0.002418076\n",
      "step: 7200, cost: 0.002384299\n",
      "step: 7300, cost: 0.002351384\n",
      "step: 7400, cost: 0.002319410\n",
      "step: 7500, cost: 0.002288273\n",
      "step: 7600, cost: 0.002257977\n",
      "step: 7700, cost: 0.002228508\n",
      "step: 7800, cost: 0.002199726\n",
      "step: 7900, cost: 0.002171717\n",
      "step: 8000, cost: 0.002144390\n",
      "step: 8100, cost: 0.002117794\n",
      "step: 8200, cost: 0.002091786\n",
      "step: 8300, cost: 0.002066428\n",
      "step: 8400, cost: 0.002041655\n",
      "step: 8500, cost: 0.002017510\n",
      "step: 8600, cost: 0.001993925\n",
      "step: 8700, cost: 0.001970863\n",
      "step: 8800, cost: 0.001948320\n",
      "step: 8900, cost: 0.001926343\n",
      "step: 9000, cost: 0.001904809\n",
      "step: 9100, cost: 0.001883775\n",
      "step: 9200, cost: 0.001863130\n",
      "step: 9300, cost: 0.001843007\n",
      "step: 9400, cost: 0.001823301\n",
      "step: 9500, cost: 0.001803966\n",
      "step: 9600, cost: 0.001785072\n",
      "step: 9700, cost: 0.001766576\n",
      "step: 9800, cost: 0.001748450\n",
      "step: 9900, cost: 0.001730708\n",
      "step: 10000, cost: 0.001713331\n"
     ]
    }
   ],
   "source": [
    "crit=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat=model(X)\n",
    "    cost=crit(y_hat, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step: %d, cost: %.9f\" %(step,cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000],\n",
      "        [0.9980],\n",
      "        [0.9980],\n",
      "        [0.0028]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat=model(X)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(2,10,bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10,10,bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10,10,bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10,1,bias=True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.751376808\n",
      "step: 100, cost: 0.560241878\n",
      "step: 200, cost: 0.553923726\n",
      "step: 300, cost: 0.448379576\n",
      "step: 400, cost: 0.025811723\n",
      "step: 500, cost: 0.007538323\n",
      "step: 600, cost: 0.004135887\n",
      "step: 700, cost: 0.002793598\n",
      "step: 800, cost: 0.002089874\n",
      "step: 900, cost: 0.001660771\n",
      "step: 1000, cost: 0.001373431\n",
      "step: 1100, cost: 0.001168276\n",
      "step: 1200, cost: 0.001014838\n",
      "step: 1300, cost: 0.000895947\n",
      "step: 1400, cost: 0.000801269\n",
      "step: 1500, cost: 0.000724162\n",
      "step: 1600, cost: 0.000660202\n",
      "step: 1700, cost: 0.000606315\n",
      "step: 1800, cost: 0.000560345\n",
      "step: 1900, cost: 0.000520651\n",
      "step: 2000, cost: 0.000486084\n",
      "step: 2100, cost: 0.000455709\n",
      "step: 2200, cost: 0.000428776\n",
      "step: 2300, cost: 0.000404747\n",
      "step: 2400, cost: 0.000383299\n",
      "step: 2500, cost: 0.000363889\n",
      "step: 2600, cost: 0.000346280\n",
      "step: 2700, cost: 0.000330298\n",
      "step: 2800, cost: 0.000315645\n",
      "step: 2900, cost: 0.000302252\n",
      "step: 3000, cost: 0.000289883\n",
      "step: 3100, cost: 0.000278468\n",
      "step: 3200, cost: 0.000267884\n",
      "step: 3300, cost: 0.000258079\n",
      "step: 3400, cost: 0.000248948\n",
      "step: 3500, cost: 0.000240419\n",
      "step: 3600, cost: 0.000232430\n",
      "step: 3700, cost: 0.000225010\n",
      "step: 3800, cost: 0.000217954\n",
      "step: 3900, cost: 0.000211324\n",
      "step: 4000, cost: 0.000205129\n",
      "step: 4100, cost: 0.000199261\n",
      "step: 4200, cost: 0.000193705\n",
      "step: 4300, cost: 0.000188385\n",
      "step: 4400, cost: 0.000183407\n",
      "step: 4500, cost: 0.000178670\n",
      "step: 4600, cost: 0.000174133\n",
      "step: 4700, cost: 0.000169874\n",
      "step: 4800, cost: 0.000165737\n",
      "step: 4900, cost: 0.000161862\n",
      "step: 5000, cost: 0.000158122\n",
      "step: 5100, cost: 0.000154570\n",
      "step: 5200, cost: 0.000151140\n",
      "step: 5300, cost: 0.000147916\n",
      "step: 5400, cost: 0.000144743\n",
      "step: 5500, cost: 0.000141736\n",
      "step: 5600, cost: 0.000138860\n",
      "step: 5700, cost: 0.000136082\n",
      "step: 5800, cost: 0.000133398\n",
      "step: 5900, cost: 0.000130863\n",
      "step: 6000, cost: 0.000128385\n",
      "step: 6100, cost: 0.000125991\n",
      "step: 6200, cost: 0.000123708\n",
      "step: 6300, cost: 0.000121503\n",
      "step: 6400, cost: 0.000119314\n",
      "step: 6500, cost: 0.000117258\n",
      "step: 6600, cost: 0.000115274\n",
      "step: 6700, cost: 0.000113329\n",
      "step: 6800, cost: 0.000111451\n",
      "step: 6900, cost: 0.000109669\n",
      "step: 7000, cost: 0.000107892\n",
      "step: 7100, cost: 0.000106176\n",
      "step: 7200, cost: 0.000104552\n",
      "step: 7300, cost: 0.000102957\n",
      "step: 7400, cost: 0.000101391\n",
      "step: 7500, cost: 0.000099852\n",
      "step: 7600, cost: 0.000098399\n",
      "step: 7700, cost: 0.000096970\n",
      "step: 7800, cost: 0.000095626\n",
      "step: 7900, cost: 0.000094244\n",
      "step: 8000, cost: 0.000092944\n",
      "step: 8100, cost: 0.000091636\n",
      "step: 8200, cost: 0.000090438\n",
      "step: 8300, cost: 0.000089228\n",
      "step: 8400, cost: 0.000088009\n",
      "step: 8500, cost: 0.000086896\n",
      "step: 8600, cost: 0.000085771\n",
      "step: 8700, cost: 0.000084664\n",
      "step: 8800, cost: 0.000083632\n",
      "step: 8900, cost: 0.000082555\n",
      "step: 9000, cost: 0.000081584\n",
      "step: 9100, cost: 0.000080596\n",
      "step: 9200, cost: 0.000079594\n",
      "step: 9300, cost: 0.000078664\n",
      "step: 9400, cost: 0.000077717\n",
      "step: 9500, cost: 0.000076874\n",
      "step: 9600, cost: 0.000075952\n",
      "step: 9700, cost: 0.000075131\n",
      "step: 9800, cost: 0.000074233\n",
      "step: 9900, cost: 0.000073435\n",
      "step: 10000, cost: 0.000072618\n"
     ]
    }
   ],
   "source": [
    "crit=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat=model(X)\n",
    "    cost=crit(y_hat, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step: %d, cost: %.9f\" %(step,cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델학습결과:  tensor([[9.9999e-01],\n",
      "        [9.9995e-01],\n",
      "        [9.9995e-01],\n",
      "        [1.7718e-04]])\n",
      "모델의 예측값:  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "실제값(Y):  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "정확도(Accuracy):  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat=model(X)\n",
    "    predicted=(y_hat>0.5).float()\n",
    "    accuracy=(predicted==Y).float().mean()\n",
    "    print(\"모델학습결과: \",y_hat)\n",
    "    print(\"모델의 예측값: \", predicted)\n",
    "    print(\"실제값(Y): \", Y)\n",
    "    print(\"정확도(Accuracy): \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
